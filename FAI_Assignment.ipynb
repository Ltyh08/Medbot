{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96dwNiq-0yKW",
        "outputId": "cacf2e35-8a2f-41dc-a7cf-d71502d40dec"
      },
      "id": "96dwNiq-0yKW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "q_O93znD00eA"
      },
      "id": "q_O93znD00eA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"aaditya/Llama3-OpenBioLLM-8B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    # Specify an offload folder\n",
        "    #offload_folder=\"offload\",\n",
        "    # or\n",
        "    # use_safetensors=True #If the model is in safetensors format\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "33101750c55b4adb8436d3acdad89715",
            "b38dc1ddcd684b90953da4cb6c030339",
            "1efc2e0eb8fb45eca2db2bee829afe55",
            "176a780100dd47779b906f9027183022",
            "675a15bd80b543d89f29ae6b7b997986",
            "699af9d17d2a48c7b31d84d1693d7eda",
            "f1d9a28e0eba494cb44c0d49a5902d31",
            "b5bd40195ed948db830a6b5ed2f6f994",
            "b68c5f0244e54d969519ff4c7f976354",
            "ff968c2ca76842a6b4c678b25cc1ac76",
            "092ac883b8c645c2ac78f74334a11288"
          ]
        },
        "id": "AMCD6Glw03UK",
        "outputId": "e91ebbf3-6ccf-4fe3-f8d4-45dfc437b0c6"
      },
      "id": "AMCD6Glw03UK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33101750c55b4adb8436d3acdad89715"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 1\n",
        "prompt_template = \"\"\"\n",
        "### Instruction:\n",
        "You are a highly knowledgeable and precise healthcare assistant. Provide clear, concise, and evidence-based information for the query below. If relevant, include references to common medical practices or guidelines.\n",
        "\n",
        "### Context:\n",
        "{context}\n",
        "\n",
        "### Question:\n",
        "{question}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate a prompt\n",
        "def generate_prompt(context: str, question: str) -> str:\n",
        "    return prompt_template.format(context=context, question=question)\n",
        "\n",
        "# Function to get response from the model\n",
        "def get_response(model, tokenizer, prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=200)\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the response part after \"Response:\"\n",
        "    response_start = full_output.find(\"### Response:\") + len(\"### Response:\")\n",
        "    response = full_output[response_start:].strip()\n",
        "    return response\n",
        "\n",
        "# Sample usage\n",
        "context = \"Query Accuracy for Medication Clarification\"\n",
        "question = \"Can I take Ibuprofen with Paracetamol?\"\n",
        "\n",
        "# Generate the prompt\n",
        "formatted_prompt = generate_prompt(context, question)\n",
        "\n",
        "# Get and print the response\n",
        "response = get_response(model, tokenizer, formatted_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "UbcAfPNU1FG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28133b6b-6fa6-4d2c-c2a1-04df2b6503ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, Ibuprofen and Paracetamol can be taken together. They have different sites of action and do not significantly interfere with each other. This combination can be effective for managing a variety of symptoms such as fever, pain, and inflammation. However, it is important to follow the recommended doses for each medication and to consult with a healthcare professional if you have any underlying medical conditions or are taking other medications to avoid potential drug interactions or side effects.\n"
          ]
        }
      ],
      "id": "UbcAfPNU1FG6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 2\n",
        "prompt_template = \"\"\"\n",
        "### Instruction:\n",
        "You are a highly knowledgeable and precise healthcare assistant. Provide clear, concise, and evidence-based information for the query below. If relevant, include references to common medical practices or guidelines.\n",
        "\n",
        "### Context:\n",
        "{context}\n",
        "\n",
        "### Question:\n",
        "{question}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate a prompt\n",
        "def generate_prompt(context: str, question: str) -> str:\n",
        "    return prompt_template.format(context=context, question=question)\n",
        "\n",
        "# Function to get response from the model\n",
        "def get_response(model, tokenizer, prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=200)\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the response part after \"Response:\"\n",
        "    response_start = full_output.find(\"### Response:\") + len(\"### Response:\")\n",
        "    response = full_output[response_start:].strip()\n",
        "    return response\n",
        "\n",
        "# Sample usage\n",
        "context = \"Symptom Analysis for Triage\"\n",
        "question = \"I have a fever of 38.5°C and a sore throat. Should I go to the doctor?\"\n",
        "\n",
        "# Generate the prompt\n",
        "formatted_prompt = generate_prompt(context, question)\n",
        "\n",
        "# Get and print the response\n",
        "response = get_response(model, tokenizer, formatted_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "ldO6N8qM1mp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f757e551-28e9-4851-b599-d6de85dbc476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the symptoms presented, a fever of 38.5°C and sore throat can be indicative of various infectious conditions such as influenza or strep throat. It is generally advised to seek medical attention if these symptoms persist or worsen. A healthcare professional will be able to assess your symptoms more thoroughly and provide appropriate advice or treatment.\n"
          ]
        }
      ],
      "id": "ldO6N8qM1mp2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 3\n",
        "prompt_template = \"\"\"\n",
        "### Instruction:\n",
        "You are a highly knowledgeable and precise healthcare assistant. Provide clear, concise, and evidence-based information for the query below. If relevant, include references to common medical practices or guidelines.\n",
        "\n",
        "### Context:\n",
        "{context}\n",
        "\n",
        "### Question:\n",
        "{question}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate a prompt\n",
        "def generate_prompt(context: str, question: str) -> str:\n",
        "    return prompt_template.format(context=context, question=question)\n",
        "\n",
        "# Function to get response from the model\n",
        "def get_response(model, tokenizer, prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=200)\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the response part after \"Response:\"\n",
        "    response_start = full_output.find(\"### Response:\") + len(\"### Response:\")\n",
        "    response = full_output[response_start:].strip()\n",
        "    return response\n",
        "\n",
        "# Sample usage\n",
        "context = \"Symptom Self-Care Guidance\"\n",
        "question = \"I have a mild headache and a runny nose. Should I see a doctor?\"\n",
        "\n",
        "# Generate the prompt\n",
        "formatted_prompt = generate_prompt(context, question)\n",
        "\n",
        "# Get and print the response\n",
        "response = get_response(model, tokenizer, formatted_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "WyHgw5_U13jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1889bc83-441d-4d1f-e586-af08e8851c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the symptoms you described, it is unlikely that you require immediate medical attention. Headaches and runny nose are commonly associated with minor health issues such as common colds or minor sinus infections, which are self-limiting and can usually be managed at home with rest and over-the-counter remedies. However, if your symptoms worsen or persist for an extended period, it would be advisable to consult a healthcare professional for further evaluation.\n"
          ]
        }
      ],
      "id": "WyHgw5_U13jd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 4\n",
        "prompt_template = \"\"\"\n",
        "### Instruction:\n",
        "You are a highly knowledgeable and precise healthcare assistant. Provide clear, concise, and evidence-based information for the query below. If relevant, include references to common medical practices or guidelines.\n",
        "\n",
        "### Context:\n",
        "{context}\n",
        "\n",
        "### Question:\n",
        "{question}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate a prompt\n",
        "def generate_prompt(context: str, question: str) -> str:\n",
        "    return prompt_template.format(context=context, question=question)\n",
        "\n",
        "# Function to get response from the model\n",
        "def get_response(model, tokenizer, prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_length=200)\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the response part after \"Response:\"\n",
        "    response_start = full_output.find(\"### Response:\") + len(\"### Response:\")\n",
        "    response = full_output[response_start:].strip()\n",
        "    return response\n",
        "\n",
        "# Sample usage\n",
        "context = \"Simulated Appointment Scheduling Assistance\"\n",
        "question = \"Can I schedule an appointment for the next available slot with Dr. Smith?\"\n",
        "\n",
        "# Generate the prompt\n",
        "formatted_prompt = generate_prompt(context, question)\n",
        "\n",
        "# Get and print the response\n",
        "response = get_response(model, tokenizer, formatted_prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "8JE7HSpA2DQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a47cd0-e2aa-46b6-ee76-a31e1543ba32"
      },
      "id": "8JE7HSpA2DQi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but without further information about the current availability of Dr. Smith's schedule, I cannot guarantee whether an appointment for the next available slot can be scheduled. It would be best to reach out directly to the clinic or medical practice to inquire about Dr. Smith's availability and to book an appointment.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33101750c55b4adb8436d3acdad89715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b38dc1ddcd684b90953da4cb6c030339",
              "IPY_MODEL_1efc2e0eb8fb45eca2db2bee829afe55",
              "IPY_MODEL_176a780100dd47779b906f9027183022"
            ],
            "layout": "IPY_MODEL_675a15bd80b543d89f29ae6b7b997986"
          }
        },
        "b38dc1ddcd684b90953da4cb6c030339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699af9d17d2a48c7b31d84d1693d7eda",
            "placeholder": "​",
            "style": "IPY_MODEL_f1d9a28e0eba494cb44c0d49a5902d31",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1efc2e0eb8fb45eca2db2bee829afe55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5bd40195ed948db830a6b5ed2f6f994",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b68c5f0244e54d969519ff4c7f976354",
            "value": 4
          }
        },
        "176a780100dd47779b906f9027183022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff968c2ca76842a6b4c678b25cc1ac76",
            "placeholder": "​",
            "style": "IPY_MODEL_092ac883b8c645c2ac78f74334a11288",
            "value": " 4/4 [00:08&lt;00:00,  1.66s/it]"
          }
        },
        "675a15bd80b543d89f29ae6b7b997986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "699af9d17d2a48c7b31d84d1693d7eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d9a28e0eba494cb44c0d49a5902d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5bd40195ed948db830a6b5ed2f6f994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68c5f0244e54d969519ff4c7f976354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff968c2ca76842a6b4c678b25cc1ac76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "092ac883b8c645c2ac78f74334a11288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}